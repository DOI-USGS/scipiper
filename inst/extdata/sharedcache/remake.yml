# Sharing a data cache within remake

# Basic approach:
# Every data file is represented by an indicator file. Indicator files get
# created once we believe a cached version exists (we just posted it, we checked
# for it, or both). Downstream files depend on the indicator files rather than
# the data files themselves. Before running any data processing scripts, the
# individual targets are pulled from the cache as need. Multiple files can be
# pulled in a single make call within the recipe, e.g., `make B.rds A.txt` The
# official targets of data analysis recipes are indicator files, not data files.
# Those recipes are responsible for ensuring that output data files do exist on
# the cache (and optionally also locally).

# include:

packages:
  - scipiper

sources:
  - demo.R
  - R.R

file_extensions: ["st","cache"]

target_default: B.rds

targets:

  # settings
  
  indicator_file_extensions:
    packages: yaml
    command: yaml.load(I("[st,s3,yeti]"))

  # project

  A.txt.st :
    command: make_cache_indicator(target_name)
    
  A.txt :
    command: get_cached_file('A.txt.st')
    
  # target_name has to be first argument. see https://github.com/richfitz/remake/issues/173
  B.rds.st :
    command: pretend_process(out_st=target_name, in_st='A.txt.st')
    depends: R.R
    
  B.rds :
    command: get_cached_file('B.rds.st')
    
  # objects need to depend on I() of data inputs (files or objects) and need to be depended
  # on as I() as well (and then retrieved within the calling function using remake::fetch);
  # if we tried to share objects as well as files, we'd need two sharing systems, both of
  # which would probably boil down to file sharing systems, which would be silly
  m : 
    command: list(p=7, d=I(-3), q=I('9'), b=I('A.txt'))
  n : 
    command: readLines(I('A.txt'))
  O.txt :
    command: do_something(obj=I('n'))

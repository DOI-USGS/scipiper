---
title: "Shared cache"
author: "Alison Appling"
date: "July 31, 2018"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Shared cache}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=FALSE, collapse=TRUE)
knitr::opts_knit$set(root.dir = tempdir())
```

## Setup

```{r libs, message=FALSE}
library(scipiper)
library(dplyr)
```

## Shared cache

A shared cache is a cloud data storage location where raw, intermediate, and/or final data products from an analysis project are contributed to and accessible by multiple analysts. Not all scipiper projects will use a shared cache.

### Pros and Cons

Advantages of a shared cache:
* Not every analyst needs to build every target, saving on total processing time.
* Targets that can only be built on specific operating systems (e.g., Mac) or in specific computing environments (e.g., a cluster) can still be accessible to all analysts for further analysis.
* Intermediate and final products can be immediately visible to anyone who has access to the shared cache, whether they are contributing to the analysis or simply inspecting/using the output.

Disadvantages of a shared cache (as currently implemented):
* In a fast-paced collaborative development environment (e.g., a 'sprint'), it is challenging to maintain synchrony between the shared cache (the data) and the git repository (the metadata). Asynchrony is not a deal-breaker but does lead to more rebuilding than would be required for a slower-paced project.
* Though we've done much to ensure this doesn't happen, it's conceivable that metadata will become corrupt relative to the data. Some monitoring and very occasional full rebuilding is recommended when practical.
* Old files no longer referenced by the code can accumulate on the shared cache unless manually deleted. Though these will not interfere with ongoing analysis, they can take up storage space unnecessarily.

### Guidelines

Projects using a shared cache should follow these guidelines:

* Use indicator files (usually an `.ind` suffix) to represent most or all of the chain of connected targets within your remake files. Each .ind file should be one of two products of a recipe, where the other product is the creation of a data file, either locally and/or in the shared cache.

* Always build targets using `scipiper::scmake()` rather than `remake::make()`. Though the functions are outwardly very similar, `scmake()` maintains an extra layer of metadata that allows multiple users to share a single project status (e.g., "file x.rds.ind is up to date; file y.rds.ind is out of date"). In a shared-cache project, you should not even need to load the `remake` package directly.

* Generally avoid using R objects as `remake/scmake` targets...but if you must, usually for convenience or conciseness of the workflow plan, recognize that R objects must be built by every analyst. So if a target takes a non-trivial length of time to build, or if it depends on large volumes of data as input, that target should usually be a file rather than an R object.

* `git commit` all .ind files (with occasional exception of .ind files within a task plan; those require additional thought). `git ignore` all data files.

* To force a rebuild, either use the `force=TRUE` argument to `scmake()` or use `scdel()` to delete indicator files. There's seldom any benefit to deleting data files (by any method); usually deleting the indicator files is plenty. When deleting indicator files, `force=TRUE` or `scdel()` are preferable to directly deleting the .ind files because if only the .ind files are deleted, the scipiper database may fail to update properly when the .ind files are rebuilt.
